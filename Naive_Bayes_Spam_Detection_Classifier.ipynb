{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jamesodukoya/NaiveBayesClassifier/blob/main/Naive_Bayes_Spam_Detection_Classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L3n85_QcDxFf"
      },
      "source": [
        "# Naive Bayes Classifier\n",
        "\n",
        "In this project, I implemented the Naive Bayes algorithm for a spam detection problem. The supervised algorithm predicts the probability of an email being in the 'spam' or 'ham' class by analyzing the words in the email based on the Bayes' Theorem. I then used log probabilites to resolve the underflow problem and improve the prediction accuracy significantly."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PfV5h21CDxFp"
      },
      "source": [
        "# Outline\n",
        "- [ 1 - Introduction](#1)\n",
        "- [ 2 - Necessary imports](#2)\n",
        "- [ 3 - The Dataset](#3)\n",
        "  - [ 3.1 Loading and Exploring the Dataset](#3.1)\n",
        "  - [ 3.2 Preprocessing the dataset](#3.2)\n",
        "  - [ 3.3 Preprocessing the text](#3.3)\n",
        "  - [ 3.4 Splitting into train/test](#3.4)\n",
        "- [ 4 - Implementing the Naive Bayes Algorithm](#4)\n",
        "  - [ 4.1 Computing $P(\\text{email} \\mid \\text{spam})$ and $P(\\text{email} \\mid \\text{ham})$](#4.1)\n",
        "  - [ 4.2 Computing $P(\\text{spam})$ and $P(\\text{ham})$](#4.2)\n",
        "  - [ 4.3 Putting all together](#4.3)\n",
        "  - [ 4.4 Model performance](#4.4)\n",
        "- [ 5 - Optimizing Classifier](#5)\n",
        "  - [ 5.1 Hidden problem in the Naive Bayes model.](#5.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ewj4iuRWDxFq"
      },
      "source": [
        "<a name=\"1\"></a>\n",
        "## 1 - Introduction\n",
        "\n",
        " This project focuses on a binary classification problem: distinguishing between spam and non-spam emails, colloquially referred to as \"ham.\" The algorithm makes a \"naive assumption\" that each feature of the model is independent of the others. Our supervised algorithm makes use of a collection of emails have already been marked as \"spam\" or \"ham\" in order to train the algorithm.\n",
        "\n",
        "### Naive Bayes for Spam Detection\n",
        "\n",
        " For the purpose of this task, spam emails will be labeled as $1$, and non-spam (ham) emails as $0$.\n",
        "\n",
        "The probability of interest for a given email is denoted as:\n",
        "\n",
        "$$ P(\\text{spam} \\mid \\text{email}) $$\n",
        "\n",
        "The higher this probability, the more likely the email is to be classified as spam. Bayes' Theorem is used in the calculation in the following way:\n",
        "\n",
        "$$ P(\\text{spam} \\mid \\text{email}) = \\frac{P(\\text{email} \\mid \\text{spam}) \\cdot P(\\text{spam})}{P(\\text{email})} $$\n",
        "\n",
        "Here's a breakdown of the terms:\n",
        "\n",
        "- $ P(\\text{spam}) $: Probability of a randomly selected email being spam, equivalent to the proportion of spam emails in the dataset.\n",
        "- $ P(\\text{email} \\mid \\text{spam}) $: Probability of a specific email occurring given that it is known to be spam.\n",
        "- $ P(\\text{email}) $: Overall probability of the email occurring.\n",
        "\n",
        "The goal of this calculation is to compare the probability an email is spam to the probability that it is ham. Here's the expression for both $ P(\\text{spam} \\mid \\text{email}) $ and $ P(\\text{ham} \\mid \\text{email}) $:\n",
        "\n",
        "$$ P(\\text{spam} \\mid \\text{email}) = \\frac{P(\\text{email} \\mid \\text{spam}) \\cdot P(\\text{spam})}{P(\\text{email})} $$\n",
        "\n",
        "$$ P(\\text{ham} \\mid \\text{email}) = \\frac{P(\\text{email} \\mid \\text{ham}) \\cdot P(\\text{ham})}{P(\\text{email})} $$\n",
        "\n",
        "Since $ P(\\text{email}) > 0 $ and it appears in both expressions, comparing the two probabilities only requires evaluating the numerators and we can ignore this denominator."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-bktMKB5DxFr"
      },
      "source": [
        "<a name=\"2\"></a>\n",
        "## 2 - Necessary imports\n",
        "\n",
        "Now, let's import all the necessary libraries and functions we need."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "graded"
        ],
        "id": "IjScePtPDxFr"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from nltk.corpus import stopwords\n",
        "from nltk import word_tokenize\n",
        "import string"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfoTIBGZDxFt"
      },
      "source": [
        "<a name=\"3\"></a>\n",
        "## 3 - The Dataset\n",
        "\n",
        "<a name=\"3.1\"></a>\n",
        "### 3.1 Loading and Exploring the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3QgtAyNxDxFu",
        "outputId": "15769e72-b971-4592-897f-8fd12a27682e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>spam</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Subject: naturally irresistible your corporate...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Subject: the stock trading gunslinger  fanny i...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Subject: unbelievable new homes made easy  im ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Subject: 4 color printing special  request add...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Subject: do not have money , get software cds ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  spam\n",
              "0  Subject: naturally irresistible your corporate...     1\n",
              "1  Subject: the stock trading gunslinger  fanny i...     1\n",
              "2  Subject: unbelievable new homes made easy  im ...     1\n",
              "3  Subject: 4 color printing special  request add...     1\n",
              "4  Subject: do not have money , get software cds ...     1"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataframe_emails = pd.read_csv('emails.csv')\n",
        "dataframe_emails.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UI7Ig3m2DxFw"
      },
      "source": [
        "Let's explore the dataset a bit:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n95YqBEuDxFw",
        "outputId": "b6cadc0a-153f-4c23-e3aa-2bafc0f686cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of emails: 5728\n",
            "Proportion of spam emails: 0.2388\n",
            "Proportion of ham emails: 0.7612\n"
          ]
        }
      ],
      "source": [
        "print(f\"Number of emails: {len(dataframe_emails)}\")\n",
        "print(f\"Proportion of spam emails: {dataframe_emails.spam.sum()/len(dataframe_emails):.4f}\")\n",
        "print(f\"Proportion of ham emails: {1-dataframe_emails.spam.sum()/len(dataframe_emails):.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swfLGNJRDxF4"
      },
      "source": [
        "As we can see, the dataset is **unbalanced**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iuCZi5DbDxF5"
      },
      "source": [
        "<a name=\"3.2\"></a>\n",
        "### 3.2 Preprocessing the dataset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DWfBDBflDxF5"
      },
      "source": [
        "The DataFrame has two columns. The one called `text` has the email's contents and the second one, called `spam` has a numerical variable telling whether the email is a spam or not. $1$ means spam and $0$ means ham (not spam). This next function will complete a couple of important pre-processing steps:\n",
        "\n",
        "* Note that every email starts with `Subject:`. This function will remove this word from the front of every email.\n",
        "* It will randomly shuffle the dataset. Right now all the spam emails are at the top of the data set followed by the ham emails. Having a shuffled dataset is critical to splitting it properly between train and test dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bjnBsytIDxF6"
      },
      "outputs": [],
      "source": [
        "def preprocess_emails(df):\n",
        "    \"\"\"\n",
        "    Preprocesses email data from a DataFrame.\n",
        "\n",
        "    Parameters:\n",
        "    - df (pandas.DataFrame): The input DataFrame containing email data with 'text' and 'spam' columns.\n",
        "\n",
        "    Returns:\n",
        "    - tuple: A tuple containing two elements:\n",
        "        1. X (numpy.array): An array containing email content after removing the \"Subject:\" prefix.\n",
        "        2. Y (numpy.array): An array indicating whether each email is spam (1) or ham (0).\n",
        "\n",
        "    The function shuffles the input DataFrame to avoid biased results in train/test splits.\n",
        "    It then extracts email content and spam labels, removing the \"Subject:\" prefix from each email.\n",
        "\n",
        "    \"\"\"\n",
        "    # Shuffles the dataset\n",
        "    df = df.sample(frac = 1, ignore_index = True, random_state = 42)\n",
        "    # Removes the \"Subject:\" string, which comprises the first 9 characters of each email. Also, convert it to a numpy array.\n",
        "    X = df.text.apply(lambda x: x[9:]).to_numpy()\n",
        "    # Convert the labels to numpy array\n",
        "    Y = df.spam.to_numpy()\n",
        "    return X, Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UCb7iHsvDxF6"
      },
      "outputs": [],
      "source": [
        "X, Y = preprocess_emails(dataframe_emails)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i22vo9Q9DxF7"
      },
      "source": [
        "Let's print the first $5$ emails:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QL-pHstGDxF7",
        "outputId": "dab81c04-e9ee-4277-a9f8-41dc1d244c07"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['re : energy derivatives conference - may 29 , toronto  good morning amy :  vince kaminski will need the following :  an lcd projector to hook up to a lap tap for his presentation  he will have dinner with the conference organizers and speakers on the 29 th .  he will need 2 nights ( the 28 th and the 29 th ) hotel reservations .  he will send you an abstract shortly .  thanks and have a great day !  shirley crenshaw  713 - 853 - 5290  amy aldous on 03 / 31 / 2000 10 : 50 : 11 am  to : shirley . crenshaw @ enron . com  cc :  subject : re : energy derivatives conference - may 29 , toronto  ms . crenshaw ,  thank you for sending the bio so quickly . it \\' s exactly what i was looking  for .  we are planning to compile the conference speakers \\' papers for distribution  to the participants . while i will not need dr . kaminski \\' s contribution for  several weeks , an abstract of his presentation as soon as possible would be  very useful to the conference organizers .  i will also need the following information :  - dr . kaminski \\' s audio / video equipment requirements for his presentation  - will he be joining the conference organizers and speakers for dinner on  may 29 ?  - which nights will he be staying in toronto ? i will reserve a room at the  conference hotel  - any dietary restrictions or special requests  your help is much appreciated .  best wishes ,  amy  at 11 : 50 am 3 / 30 / 00 - 0600 , you wrote :  >  > amy :  >  > attached please find a short \" bio \" for dr . kaminski . please let me know  > if i can help further .  >  >  > ( see attached file : vincent kaminski bio . doc )  * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *  amy aldous , conference co - ordinator  centre for advanced studies in finance  university of waterloo  waterloo , on n 2 l 3 gl  tel : ( 519 ) 888 - 4567 ext . 5728  fax : ( 519 ) 888 - 7562  email : aaldous @ uwaterloo . ca  * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *'\n",
            " 'financial maths course , part 2  vince ,  just in case , here is a draft copy of the event for you to refer to .  paul  - finmathmail . doc'\n",
            " 're : bullet points  please respond to hi vince ,  thanks for the bullets . regarding power 2001 , it certainly does promise to  be a very interesting event .  have a great week ,  paul  - - - - - original message - - - - -  from : vince . j . kaminski @ enron . com [ mailto : vince . j . kaminski @ enron . com ]  sent : monday , april 09 , 2001 9 : 11 am  to : pbristow @ riskwaters . com  cc : vince . j . kaminski @ enron . com ; vkaminski @ aol . com  subject : bullet points  paul ,  i am sending you modified bullet points . the modifications are in red .  apologies for a delay in responding to your messages .  by the way , power 2001 gets only more and more interesting every day .  vince  ( see attached file : financial maths draft . doc )'\n",
            " 're : enron default swaps  darrell ,  i am sending you 2 technical notes on enron default swaps : i hope that they  will  be useful . i shall read the articles on weekend . i am curious if you  find these explanations satisfactory .  we are very slow in preparing a number of technical documents  for you for model reviews . we still hope you will be able  to find some time to review our credit models ( for our london  credit trading ) and var and option pricing related models .  also , please check your invoices . i still think we owe you money .  vince  darrell duffie on 03 / 28 / 2001 08 : 07 : 38 am  to : vince j kaminski  cc :  subject : re : enron default swaps  vince : according to a bank of america  publication , your ( enron ) default swap spreads  are consistently trading about 80  basis points wider than your asset swaps .  any idea of what is going on here ?  thanks for any guidance , darrell  darrell duffie  mail gsb stanford ca 94305 - 5015 usa  phone 650 723 1976  fax 650 725 7979  email duffie @ stanford . edu  web http : / / www . stanford . edu / ~ duffie / '\n",
            " 're : power question  steve ,  elena chilkina can give you historical data .  historical fwd curves can be obtained from paulo  or alex , among others . of course , our internal forward curves  represent a very sensitive information .  vince  steven leppard  10 / 13 / 2000 10 : 34 am  to : vince j kaminski / hou / ect @ ect  cc : didier magne / lon / ect @ ect  subject : power question  hi vince  who should i contact for power queries now grant has gone ? a colleague here  in london ( didier magne ) is giving a talk on power / gas arbitrage , and the  consequent convergence of these markets .  do you have any presentations on this area , or illustrative figures on the  increase in power / gas correlation ?  many thanks ,  steve']\n"
          ]
        }
      ],
      "source": [
        "print(X[:5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q0WbnlXcDxF8"
      },
      "source": [
        "And the first $5$ labels:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5vW6tZg9DxF8",
        "outputId": "ec0f4d84-d503-4278-dab6-642cd09e8739"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0 0 0 0 0]\n"
          ]
        }
      ],
      "source": [
        "print(Y[:5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uxItmalwDxF-"
      },
      "source": [
        "<a name=\"3.3\"></a>\n",
        "### 3.3 Preprocessing the text\n",
        "\n",
        "In text, usually there are some words that don't provide much information about what the text is saying, such as prepositions, pronouns and so on. These are called **stopwords**. The idea is to remove all these stopwords and punctuation, so in the end we can have a simpler set of words to deal with.\n",
        "\n",
        "Another step is the emails **tokenization**. To tokenize is to split the email into **tokens**, which are essentially the words in it. As a result, for each email, the final result will be a NumPy array consisting of every word in the email without stopwords and punctuation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rNo2AY6rDxF-"
      },
      "outputs": [],
      "source": [
        "def preprocess_text(X):\n",
        "    \"\"\"\n",
        "    Preprocesses a collection of text data by removing stopwords and punctuation.\n",
        "\n",
        "    Parameters:\n",
        "    - X (str or array-like): The input text data to be processed. If a single string is provided,\n",
        "      it will be converted into a one-element numpy array.\n",
        "\n",
        "    Returns:\n",
        "    - numpy.array: An array of preprocessed text data, where each element represents a document\n",
        "      with stopwords and punctuation removed.\n",
        "\n",
        "    Note:\n",
        "    - The function uses the Natural Language Toolkit (nltk) library for tokenization and stopword removal.\n",
        "    - If the input is a single string, it is converted into a one-element numpy array.\n",
        "    \"\"\"\n",
        "    # Make a set with the stopwords and punctuation\n",
        "    stop = set(stopwords.words('english') + list(string.punctuation))\n",
        "\n",
        "    # The next lines will handle the case where a single email is passed instead of an array of emails.\n",
        "    if isinstance(X, str):\n",
        "        X = np.array([X])\n",
        "\n",
        "    # The result will be stored in a list\n",
        "    X_preprocessed = []\n",
        "\n",
        "    for i, email in enumerate(X):\n",
        "        email = np.array([i.lower() for i in word_tokenize(email) if i.lower() not in stop]).astype(X.dtype)\n",
        "        X_preprocessed.append(email)\n",
        "\n",
        "    if len(X) == 1:\n",
        "        return X_preprocessed[0]\n",
        "    return X_preprocessed\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-TCIyphnDxF_"
      },
      "outputs": [],
      "source": [
        "X_treated = preprocess_text(X)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yViZ5BrKDxF_"
      },
      "source": [
        "After the pre-processing, the text of each email has been turned into a numpy array with all the stop words below. The example here shows how a randomly selected `email_index` value (in this case 989) looks before and after this processing step. This cleaned up array of words for each email will be what is actually used by the algorithm."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AFmyMBkCDxF_",
        "outputId": "cc569d0e-c75a-49c6-fb4f-62ccb4008c69"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Email before preprocessing: marketing for your espeak session  vince :  thanks for your time earlier this week ; i ' m looking forward to your espeak  event .  sarah and i met with our etv contact yesterday , and we will be able to put a  bulleted list on the elevator screens to advertise your espeak . please let  me know what you would like us to post for you , and we will do the rest !  we also have plans to market specifically to the trader community here at  enron , so you should get a high participation rate , especially from those  groups .  thanks , again .  - er\n",
            "Email after preprocessing: ['marketing' 'espeak' 'session' 'vince' 'thanks' 'time' 'earlier' 'week'\n",
            " 'looking' 'forward' 'espeak' 'event' 'sarah' 'met' 'etv' 'contact'\n",
            " 'yesterday' 'able' 'put' 'bulleted' 'list' 'elevator' 'screens'\n",
            " 'advertise' 'espeak' 'please' 'let' 'know' 'would' 'like' 'us' 'post'\n",
            " 'rest' 'also' 'plans' 'market' 'specifically' 'trader' 'community'\n",
            " 'enron' 'get' 'high' 'participation' 'rate' 'especially' 'groups'\n",
            " 'thanks' 'er']\n"
          ]
        }
      ],
      "source": [
        "email_index = 989\n",
        "print(f\"Email before preprocessing: {X[email_index]}\")\n",
        "print(f\"Email after preprocessing: {X_treated[email_index]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aPGchk_ADxGA"
      },
      "source": [
        "<a name=\"3.4\"></a>\n",
        "### 3.4 Splitting into train/test\n",
        "\n",
        "Next, let's split our dataset into train and test sets. 80% of the data will be used for training and 20% for testing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kmi7-5CZDxGA"
      },
      "outputs": [],
      "source": [
        "TRAIN_SIZE = int(0.80*len(X_treated)) # 80% of the samples will be used to train.\n",
        "\n",
        "X_train = X_treated[:TRAIN_SIZE]\n",
        "Y_train = Y[:TRAIN_SIZE]\n",
        "X_test = X_treated[TRAIN_SIZE:]\n",
        "Y_test = Y[TRAIN_SIZE:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i81F5Y2QDxGB"
      },
      "source": [
        "Let's check if the original proportion of spam mails remains roughly the same in the train and test datasets. This helps to avoid building a biased algorithm."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TzkQnUzhDxGB",
        "outputId": "38dca7cb-5695-4e1b-87be-3ee0316d69f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Proportion of spam in train dataset: 0.2431\n",
            "Proportion of spam in test dataset: 0.2216\n"
          ]
        }
      ],
      "source": [
        "print(f\"Proportion of spam in train dataset: {sum(Y_train == 1)/len(Y_train):.4f}\")\n",
        "print(f\"Proportion of spam in test dataset: {sum(Y_test == 1)/len(Y_test):.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SAffOgWiDxGC"
      },
      "source": [
        "<a name=\"4\"></a>\n",
        "## 4 - Implementing the Naive Bayes Algorithm\n",
        "\n",
        "<a name=\"4.1\"></a>\n",
        "### 4.1 Computing $P(\\text{email} \\mid \\text{spam})$ and $P(\\text{email} \\mid \\text{ham})$\n",
        "\n",
        "Both $P(\\text{email} \\mid \\text{spam})$ and $P(\\text{email} \\mid \\text{ham})$ cases work identically, so let's start on the spam case.\n",
        "\n",
        "Each email is a list of words. Our goal is to calculate how likely one is to see this list of words, given the email is spam. The way to do that is to apply the product rule. Representing an email as $\\text{email} = \\{\\text{word}_1, \\text{word}_2, \\ldots, \\text{word}_n \\}$, the computation is:\n",
        "\n",
        "$$P(\\text{email} \\mid \\text{spam}) = P(\\text{word}_1 \\mid \\text{spam}) \\cdot P(\\text{word}_2 \\mid \\text{spam}) \\cdots P(\\text{word}_n \\mid \\text{spam})$$\n",
        "\n",
        "This is where we make the **naive assumption**, hence \"Naive Bayes\"! We will assume that each word's probability of appearing in an email is independent of each other word's probability. This assumption, of course, is false. Emails that contain the word \"party\" are probably more likely to include the word \"invitation\". Emails that contain the word \"prize\" are probably more likely to include the word \"congratulations\". By making a false assumption that these probabilities are independent, however, we gain the ability to apply the product rule. Rather than accounting for a complex set of conditional probabilities between words, we can simply assume independence and multiply a fairly simple set of conditional probabilities as shown in the expression above. Naive Bayes is built on an inaccurate assumption about our data, but based on empirical evidence, it often yields impressive results!\n",
        "\n",
        "Here's how we'd actually calculate the probability of $\\text{word}_1$ appearing in an email, given it's spam:\n",
        "\n",
        "$$P(\\text{word}_1 \\mid \\text{spam}) = \\frac{\\text{\\# spam emails with } \\text{word}_1}{\\text{\\# spam emails}}$$\n",
        "\n",
        "Where the symbol \\# means the number of elements, i.e., $\\text{\\# spam emails with } \\text{word}_1$ means the amount of spam emails with $\\text{word}_1$.\n",
        "\n",
        "To achieve this, **our first task will be to create a dictionary named `word_frequency` to store the frequency with which every word in the dataset appears in ham and spam emails**\n",
        "\n",
        "#### 4.1.1 Handling 0 in the Product\n",
        "\n",
        "Encountering a word that only appears in spam emails or never appears in a spam email may result in $P(\\text{word} \\mid \\text{spam}) = 0$ (or the ham analog), leading to the entire product being $0$. This scenario is undesirable as a single word could make the entire probability $0$. To mitigate this, we will **start by counting spam/ham appearances for every word from 1**. By artificially assuming that there is at least one spam and one ham email with every word, we eliminate the possibility of $0$ appearing in the computations.\n",
        "\n",
        "<a name=\"4.2\"></a>\n",
        "### 4.2 Computing $P(\\text{spam})$ and $P(\\text{ham})$\n",
        "\n",
        "When using Bayes Theorem, we'll also need to include the overall probability of seeing ham and spam emails. This computation is fairly easy since they are just the proportion of spam and ham emails in the dataset.\n",
        "\n",
        "$$P(\\text{spam}) = \\frac{\\text{\\# spam emails}}{\\text{\\# total emails}}$$\n",
        "$$P(\\text{ham}) = \\frac{\\text{\\# ham emails}}{\\text{\\# total emails}}$$\n",
        "\n",
        "<a name=\"4.3\"></a>\n",
        "### 4.3 Putting all together\n",
        "\n",
        "To calculate the probability an email is spam or ham, we just need to multiply the terms we've already calculated and compare which one is bigger.\n",
        "\n",
        "- $P(\\text{spam}) \\cdot P(\\text{email} \\mid \\text{spam})$\n",
        "- $P(\\text{ham}) \\cdot P(\\text{email} \\mid \\text{ham})$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u0hGyH3lDxGC"
      },
      "source": [
        "\n",
        "Our task now is to implement the function that generates a dictionary, recording the frequency with which each word in the dataset appears as spam (1) or ham (0)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "graded"
        ],
        "id": "2jdw-_PyDxGD"
      },
      "outputs": [],
      "source": [
        "def get_word_frequency(X,Y):\n",
        "    \"\"\"\n",
        "    Calculate the frequency of each word in a set of emails categorized as spam (1) or not spam (0).\n",
        "\n",
        "    Parameters:\n",
        "    - X (numpy.array): Array of emails, where each email is represented as a list of words.\n",
        "    - Y (numpy.array): Array of labels corresponding to each email in X. 1 indicates spam, 0 indicates ham.\n",
        "\n",
        "    Returns:\n",
        "    - word_dict (dict): A dictionary where keys are unique words found in the emails, and values\n",
        "      are dictionaries containing the frequency of each word for spam (1) and not spam (0) emails.\n",
        "    \"\"\"\n",
        "    # Creates an empty dictionary\n",
        "    word_dict = {}\n",
        "\n",
        "\n",
        "    num_emails = len(X)\n",
        "\n",
        "    # Iterates over every processed email and its label\n",
        "    for i in range(num_emails):\n",
        "        # Get the i-th email\n",
        "        email = X[i]\n",
        "        # Get the i-th label. This indicates whether the email is spam or not. 1 = None\n",
        "        # The variable name cls is an abbreviation for class, a reserved word in Python.\n",
        "        cls = Y[i]\n",
        "        # To avoid counting the same word twice in an email, remove duplicates by casting the email as a set\n",
        "        email = set(email)\n",
        "        # Iterates over every distinct word in the email\n",
        "        for word in email:\n",
        "            # If the word is not already in the dictionary, manually add it. Remember that we will start every word count as 1 both in spam and ham\n",
        "            if word not in word_dict.keys():\n",
        "                word_dict[word] = {'spam': 1, 'ham': 1}\n",
        "            # Add one occurrence for that specific word in the key ham if cls == 0 and spam if cls == 1.\n",
        "            if cls == 0:\n",
        "                word_dict[word]['ham'] += 1\n",
        "            if cls == 1:\n",
        "                word_dict[word]['spam'] += 1\n",
        "\n",
        "    return word_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lOxamB87DxGK",
        "outputId": "41e30c65-1915-467f-da0d-1a33b5d323d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'going': {'spam': 2, 'ham': 1}, 'like': {'spam': 2, 'ham': 1}, 'river': {'spam': 2, 'ham': 3}, 'deep': {'spam': 1, 'ham': 2}, 'love': {'spam': 1, 'ham': 2}, 'hate': {'spam': 1, 'ham': 2}}\n"
          ]
        }
      ],
      "source": [
        "test_output = get_word_frequency([['like','going','river'], ['love', 'deep', 'river'], ['hate','river']], [1,0,0])\n",
        "print(test_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "wthcot4ADxGM"
      },
      "outputs": [],
      "source": [
        "# This will build the word_frequency dictionary using the training set.\n",
        "word_frequency = get_word_frequency(X_train,Y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6dnobUQnDxGu"
      },
      "source": [
        "We will also need a class frequency dictionary. This will store the total number of ham (0) and spam (1) emails in the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "Z8FAphHHDxGu"
      },
      "outputs": [],
      "source": [
        "# To count the spam and ham emails, we may just sum the respective 1 and 0 values in the training dataset, since the convention is spam = 1 and ham = 0.\n",
        "class_frequency = {'ham': sum(Y_train == 0), 'spam': sum(Y_train == 1)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p9h1NfNxDxGu",
        "outputId": "7fb6b3a8-5645-4150-ab5e-94620b10240b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'ham': 3468, 'spam': 1114}\n"
          ]
        }
      ],
      "source": [
        "print(class_frequency)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJjWtKNiDxGv"
      },
      "source": [
        "Next, we'll retrieve the proportion of spam in the training dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u7axPL_dDxGv",
        "outputId": "afa4eb28-ef35-453c-a181-2216931da075"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The proportion of spam emails in training is: 0.2431\n"
          ]
        }
      ],
      "source": [
        "# The idea is to compute  (amount of spam emails)/(total emails).\n",
        "# Since an email is either spam or ham, total emails = (amount of ham emails) + (amount of spam emails).\n",
        "proportion_spam = class_frequency['spam']/(class_frequency['ham'] + class_frequency['spam'])\n",
        "print(f\"The proportion of spam emails in training is: {proportion_spam:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mpl4RYQaDxGw"
      },
      "source": [
        "<a name=\"ex02\"></a>\n",
        "\n",
        "In the next step, we will implement the function to compute $P(\\text{word} \\mid \\text{spam})$ and $P(\\text{word} \\mid \\text{ham})$. Since the computations are the same for both types of emails, you will create a function to compute $P(\\text{word} \\mid \\text{class})$ where class can be either spam ($1$) or (ham) $0$.\n",
        "\n",
        "Remember that\n",
        "\n",
        "$$P(\\text{word}_i \\mid \\text{class}) = \\frac{\\text{\\# emails in the class (either spam or ham) containing } \\text{word}_i}{\\text{\\# emails in the given class (spam or ham)}}$$\n",
        "\n",
        "**For now we won't worry about whether a word is present or not in the dictionary. This will be handled in later functions.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "graded"
        ],
        "id": "p7Mis-0aDxGx"
      },
      "outputs": [],
      "source": [
        "def prob_word_given_class(word, cls, word_frequency, class_frequency):\n",
        "    \"\"\"\n",
        "    Calculate the conditional probability of a given word occurring in a specific class.\n",
        "\n",
        "    Parameters:\n",
        "    - word (str): The target word for which the probability is calculated.\n",
        "    - cls (str): The class for which the probability is calculated, it may be 'spam' or 'ham'\n",
        "    - word_frequency (dict): The dictionary containing the words frequency.\n",
        "    - class_frequency (dict): The dictionary containing the class frequency.\n",
        "\n",
        "    Returns:\n",
        "    - float: The conditional probability of the given word occurring in the specified class.\n",
        "    \"\"\"\n",
        "\n",
        "    # Get the amount of times the word appears with the given class (class is stores in spam variable)\n",
        "    amount_word_and_class = word_frequency[word][cls]\n",
        "    p_word_given_class = amount_word_and_class/class_frequency[cls]\n",
        "\n",
        "    return p_word_given_class\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w9zjZjwmDxGx",
        "outputId": "15f0d1f3-9cf2-4dc4-8cbc-64dfae72be5b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "P(lottery | spam) = 0.00807899461400359\n",
            "P(lottery | ham) = 0.0002883506343713956\n",
            "P(schedule | spam) = 0.008976660682226212\n",
            "P(schedule | ham) = 0.10294117647058823\n"
          ]
        }
      ],
      "source": [
        "print(f\"P(lottery | spam) = {prob_word_given_class('lottery', cls = 'spam', word_frequency = word_frequency, class_frequency = class_frequency)}\")\n",
        "print(f\"P(lottery | ham) = {prob_word_given_class('lottery', cls = 'ham', word_frequency = word_frequency, class_frequency = class_frequency)}\")\n",
        "print(f\"P(schedule | spam) = {prob_word_given_class('schedule', cls = 'spam', word_frequency = word_frequency, class_frequency = class_frequency)}\")\n",
        "print(f\"P(schedule | ham) = {prob_word_given_class('schedule', cls = 'ham', word_frequency = word_frequency, class_frequency = class_frequency)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQC1KfGEDxG0"
      },
      "source": [
        "<a name=\"ex03\"></a>\n",
        "\n",
        "Next, we will implement the function to compute $P(\\text{email} \\mid \\text{class})$ where class can be either spam (1) or ham (0). We introduce the *naive assumption* that\n",
        "\n",
        "$$P(\\text{email} \\mid \\text{class}) = P(\\text{word}_1 \\mid \\text{class}) \\cdot P(\\text{word}_2 \\mid \\text{class}) \\cdots P(\\text{word}_n \\mid \\text{class})$$\n",
        "\n",
        "The idea is to iterate over every word in the email and in each step, update the probability by multiplying it with the value for $P(\\text{word} \\mid \\text{class})$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "graded"
        ],
        "id": "QcGenDHODxG1"
      },
      "outputs": [],
      "source": [
        "def prob_email_given_class(treated_email, cls, word_frequency, class_frequency):\n",
        "    \"\"\"\n",
        "    Calculate the probability of an email being of a certain class (e.g., spam or ham) based on treated email content.\n",
        "\n",
        "    Parameters:\n",
        "    - treated_email (list): A list of treated words in the email.\n",
        "    - cls (str): The class label for the email. It can be either 'spam' or 'ham'\n",
        "    - word_frequency (dict): The dictionary containing the words frequency.\n",
        "    - class_frequency (dict): The dictionary containing the class frequency.\n",
        "\n",
        "    Returns:\n",
        "    - float: The probability of the given email belonging to the specified class.\n",
        "    \"\"\"\n",
        "\n",
        "    # prob starts at 1 because it will be updated by multiplying it with the current P(word | class) in every iteration\n",
        "    prob = 1\n",
        "\n",
        "\n",
        "    for word in treated_email:\n",
        "        # Only perform the computation for words that exist in the word frequency dictionary\n",
        "        if word in word_frequency.keys():\n",
        "            # Update the prob by multiplying it with P(word | class).\n",
        "            prob *= word_frequency[word][cls]/class_frequency[cls]\n",
        "\n",
        "    return prob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C_9lIIrXDxG1",
        "outputId": "a72bb28f-67f4-4fc2-bed2-a267cd26f952"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Email: Click here to win a lottery ticket and claim your prize!\n",
            "Email after preprocessing: ['click' 'win' 'lottery' 'ticket' 'claim' 'prize']\n",
            "P(email | spam) = 5.3884806600117164e-11\n",
            "P(email | ham) = 1.2428344868918976e-15\n"
          ]
        }
      ],
      "source": [
        "example_email = \"Click here to win a lottery ticket and claim your prize!\"\n",
        "treated_email = preprocess_text(example_email)\n",
        "prob_spam = prob_email_given_class(treated_email, cls = 'spam', word_frequency = word_frequency, class_frequency = class_frequency)\n",
        "prob_ham = prob_email_given_class(treated_email, cls = 'ham', word_frequency = word_frequency, class_frequency = class_frequency)\n",
        "print(f\"Email: {example_email}\\nEmail after preprocessing: {treated_email}\\nP(email | spam) = {prob_spam}\\nP(email | ham) = {prob_ham}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T3CFcDbXDxG3"
      },
      "source": [
        "<a name=\"ex04\"></a>\n",
        "In this section, we will perform both computations below to calculate the probability an email is either spam or ham:\n",
        "\n",
        "- $ P(\\text{spam}) \\cdot P(\\text{email} \\mid \\text{spam}) $\n",
        "\n",
        "- $ P(\\text{ham}) \\cdot P(\\text{email} \\mid \\text{ham})$\n",
        "\n",
        "The one with the greatest value will be the class oour algorithm assigns to that email. Note that the function below includes a parameter that tells the function to return both probabilities rather than the class that was chosen.\n",
        "\n",
        "**Note**: Output will be an integer, indicating the respective email class. If the email is predicted as spam and ham, it would be possible to return spam or ham. However, having the model output a number helps further computation, such as metrics to evaluate the model performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "graded"
        ],
        "id": "ksKPqSJsDxG4"
      },
      "outputs": [],
      "source": [
        "def naive_bayes(treated_email, word_frequency, class_frequency, return_likelihood = False):\n",
        "    \"\"\"\n",
        "    Naive Bayes classifier for spam detection.\n",
        "\n",
        "    This function calculates the probability of an email being spam (1) or ham (0)\n",
        "    based on the Naive Bayes algorithm. It uses the conditional probabilities of the\n",
        "    treated_email given spam and ham, as well as the prior probabilities of spam and ham\n",
        "    classes. The final decision is made by comparing the calculated probabilities.\n",
        "\n",
        "    Parameters:\n",
        "    - treated_email (list): A preprocessed representation of the input email.\n",
        "    - word_frequency (dict): The dictionary containing the words frequency.\n",
        "    - class_frequency (dict): The dictionary containing the class frequency.\n",
        "        - return_likelihood (bool): If true, it returns the likelihood of both spam and ham.\n",
        "\n",
        "    Returns:\n",
        "    If return_likelihood = False:\n",
        "        - int: 1 if the email is classified as spam, 0 if classified as ham.\n",
        "    If return_likelihood = True:\n",
        "        - tuple: A tuple with the format (spam_likelihood, ham_likelihood)\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    # Compute P(email | spam) with the function you defined just above.\n",
        "    prob_email_given_spam = prob_email_given_class(treated_email, 'spam', word_frequency, class_frequency)\n",
        "\n",
        "    # Compute P(email | ham) with the function you defined just above.\n",
        "    prob_email_given_ham = prob_email_given_class(treated_email, 'ham', word_frequency, class_frequency)\n",
        "\n",
        "    # Compute P(spam) using the class_frequency dictionary and using the formula #spam emails / #total emails\n",
        "    p_spam = class_frequency['spam']/len(treated_email)\n",
        "\n",
        "    # Compute P(ham) using the class_frequency dictionary and using the formula #ham emails / #total emails\n",
        "    p_ham = class_frequency['ham']/len(treated_email)\n",
        "\n",
        "    # Compute the quantity P(spam) * P(email | spam), let's call it spam_likelihood\n",
        "    spam_likelihood = p_spam * prob_email_given_spam\n",
        "\n",
        "    # Compute the quantity P(ham) * P(email | ham), let's call it ham_likelihood\n",
        "    ham_likelihood = p_ham * prob_email_given_ham\n",
        "\n",
        "\n",
        "\n",
        "    # In case of passing return_likelihood = True, then return the desired tuple\n",
        "    if return_likelihood == True:\n",
        "        return (spam_likelihood, ham_likelihood)\n",
        "\n",
        "    # Compares both values and choose the class corresponding to the higher value\n",
        "    elif spam_likelihood >= ham_likelihood:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9IN1LjNXDxG5",
        "outputId": "0184126a-31c4-4bfe-ed4c-424b436f1499"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Email: Click here to win a lottery ticket and claim your prize!\n",
            "Email after preprocessing: ['click' 'win' 'lottery' 'ticket' 'claim' 'prize']\n",
            "Naive Bayes predicts this email as: 1\n",
            "\n",
            "\n",
            "\n",
            "Email: Our meeting will happen in the main office. Please be there in time.\n",
            "Email after preprocessing: ['meeting' 'happen' 'main' 'office' 'please' 'time']\n",
            "Naive Bayes predicts this email as: 0\n"
          ]
        }
      ],
      "source": [
        "example_email = \"Click here to win a lottery ticket and claim your prize!\"\n",
        "treated_email = preprocess_text(example_email)\n",
        "\n",
        "print(f\"Email: {example_email}\\nEmail after preprocessing: {treated_email}\\nNaive Bayes predicts this email as: {naive_bayes(treated_email, word_frequency, class_frequency)}\")\n",
        "\n",
        "print(\"\\n\\n\")\n",
        "example_email = \"Our meeting will happen in the main office. Please be there in time.\"\n",
        "treated_email = preprocess_text(example_email)\n",
        "\n",
        "print(f\"Email: {example_email}\\nEmail after preprocessing: {treated_email}\\nNaive Bayes predicts this email as: {naive_bayes(treated_email, word_frequency, class_frequency)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dnPbYnZeDxG8"
      },
      "source": [
        "<a name=\"4.4\"></a>\n",
        "### 4.4 Model performance\n",
        "In this section, we will explore the performance of the model we've just built. Recall that we trained the model on 80% of the data, and randomly preserved 20% of the data as test data.\n",
        "\n",
        "To compute the prediction accuracy, we must:\n",
        "\n",
        "- Count every spam email that the model correctly classifies as spam (these are called **true positives**)\n",
        "- Count every ham email that the model correctly classifies as ham (these are called **true negatives**)\n",
        "\n",
        "Finally, to get a proportion, we divide the sum of the true positives and true negatives by the total number of observations. If the model is perfect, then the accuracy would be 1, or 100%."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qfKwTdxODxG9"
      },
      "outputs": [],
      "source": [
        "def get_true_positives(Y_true, Y_pred):\n",
        "    \"\"\"\n",
        "    Calculate the number of true positive instances in binary classification.\n",
        "\n",
        "    Parameters:\n",
        "    - Y_true (list): List of true labels (0 or 1) for each instance.\n",
        "    - Y_pred (list): List of predicted labels (0 or 1) for each instance.\n",
        "\n",
        "    Returns:\n",
        "    - int: Number of true positives, where true label and predicted label are both 1.\n",
        "    \"\"\"\n",
        "    # Both Y_true and Y_pred must match in length.\n",
        "    if len(Y_true) != len(Y_pred):\n",
        "        return \"Number of true labels and predict labels must match!\"\n",
        "    n = len(Y_true)\n",
        "    true_positives = 0\n",
        "    # Iterate over the number of elements in the list\n",
        "    for i in range(n):\n",
        "        # Get the true label for the considered email\n",
        "        true_label_i = Y_true[i]\n",
        "        # Get the predicted (model output) for the considered email\n",
        "        predicted_label_i = Y_pred[i]\n",
        "        # Increase the counter by 1 only if true_label_i = 1 and predicted_label_i = 1 (true positives)\n",
        "        if true_label_i == 1 and predicted_label_i == 1:\n",
        "            true_positives += 1\n",
        "    return true_positives\n",
        "\n",
        "def get_true_negatives(Y_true, Y_pred):\n",
        "    \"\"\"\n",
        "    Calculate the number of true negative instances in binary classification.\n",
        "\n",
        "    Parameters:\n",
        "    - Y_true (list): List of true labels (0 or 1) for each instance.\n",
        "    - Y_pred (list): List of predicted labels (0 or 1) for each instance.\n",
        "\n",
        "    Returns:\n",
        "    - int: Number of true negatives, where true label and predicted label are both 0.\n",
        "    \"\"\"\n",
        "\n",
        "    # Both Y_true and Y_pred must match in length.\n",
        "    if len(Y_true) != len(Y_pred):\n",
        "        return \"Number of true labels and predict labels must match!\"\n",
        "    n = len(Y_true)\n",
        "    true_negatives = 0\n",
        "    # Iterate over the number of elements in the list\n",
        "    for i in range(n):\n",
        "        # Get the true label for the considered email\n",
        "        true_label_i = Y_true[i]\n",
        "        # Get the predicted (model output) for the considered email\n",
        "        predicted_label_i = Y_pred[i]\n",
        "        # Increase the counter by 1 only if true_label_i = 0 and predicted_label_i = 0 (true negatives)\n",
        "        if true_label_i == 0 and predicted_label_i == 0:\n",
        "            true_negatives += 1\n",
        "    return true_negatives\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "888C_a7lDxG-",
        "outputId": "831414df-f51e-4cb4-98a5-1cab695ddf6d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Y_test and Y_pred matches in length? Answer: True\n"
          ]
        }
      ],
      "source": [
        "# Let's get the predictions for the test set:\n",
        "\n",
        "# Create an empty list to store the predictions\n",
        "Y_pred = []\n",
        "\n",
        "\n",
        "# Iterate over every email in the test set\n",
        "for email in X_test:\n",
        "    # Perform prediction\n",
        "    prediction = naive_bayes(email, word_frequency, class_frequency)\n",
        "    # Add it to the list\n",
        "    Y_pred.append(prediction)\n",
        "\n",
        "# Checking if both Y_pred and Y_test (these are the true labels) match in length:\n",
        "print(f\"Y_test and Y_pred matches in length? Answer: {len(Y_pred) == len(Y_test)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P2ea3yDPDxG_",
        "outputId": "5df200ae-fef8-4c40-bd90-673ffff86906"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of true positives is: 249\n",
            "The number of true negatives is: 723\n",
            "Accuracy is: 0.8482\n"
          ]
        }
      ],
      "source": [
        "# Get the number of true positives:\n",
        "true_positives = get_true_positives(Y_test, Y_pred)\n",
        "\n",
        "# Get the number of true negatives:\n",
        "true_negatives = get_true_negatives(Y_test, Y_pred)\n",
        "\n",
        "print(f\"The number of true positives is: {true_positives}\\nThe number of true negatives is: {true_negatives}\")\n",
        "\n",
        "# Compute the accuracy by summing true negatives with true positives and dividing it by the total number of elements in the dataset.\n",
        "# Since both Y_pred and Y_test have the same length, it does not matter which one you use.\n",
        "accuracy = (true_positives + true_negatives)/len(Y_test)\n",
        "\n",
        "print(f\"Accuracy is: {accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ke8f9EdODxG_"
      },
      "source": [
        "With this basic approach, the model reaches an accuracy of 84.82%! Let's compose our own email and experiment with the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RDnOJPHHDxHA",
        "outputId": "5f4e086e-b50c-4d7b-e643-28f7334252f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The email is: Don't be worried! You haven't won a lottery prize! Congratulations! Click here to claim it\n",
            "The model predicts it as spam.\n"
          ]
        }
      ],
      "source": [
        "#email = \"Please meet me in 2 hours in the main building. I have an important task for you.\"\n",
        "email = \"Don't be worried! You haven't won a lottery prize! Congratulations! Click here to claim it\"\n",
        "\n",
        "# Preprocess the email\n",
        "treated_email = preprocess_text(email)\n",
        "# Get the prediction, in order to print it nicely, if the output is 1 then the prediction will be written as \"spam\" otherwise \"ham\".\n",
        "prediction = \"spam\" if naive_bayes(treated_email, word_frequency, class_frequency) == 1 else \"ham\"\n",
        "print(f\"The email is: {email}\\nThe model predicts it as {prediction}.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nXvhjVMsDxHB"
      },
      "source": [
        "<a name=\"5\"></a>\n",
        "## 5 - Optimizing the Classifier\n",
        "<a name=\"5.1\"></a>\n",
        "### 5.1 Hidden problem in the Naive Bayes model.\n",
        "\n",
        "Let's manually perform the Naive Bayes computation on a specific example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NWDgbXTfDxHB",
        "outputId": "e0debaaf-66d6-45f7-abd1-76c907d8c3a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The email is:\n",
            "\tfrom the enron india newsdesk - may 5 - 7 newsclips  stinson / vince ,  some news articles . do read the first one , and the second last one .  regards ,  sandeep .  - - - - - - - - - - - - - - - - - - - - - - forwarded by sandeep kohli / enron _ development on  05 / 07 / 2001 09 : 10 am - - - - - - - - - - - - - - - - - - - - - - - - - - -  nikita varma  05 / 07 / 2001 07 : 42 am  to : nikita varma / enron _ development @ enron _ development  cc : ( bcc : sandeep kohli / enron _ development )  subject : from the enron india newsdesk - may 5 - 7 newsclips  the economic times , may 7 , 2001  enron ceo casts vote to save dpc , tina edwin & soma banerjee  - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  the economic times , may 7 , 2001  maha sore over delay in naming godbole nominee  - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  the times of india , 7 may , 2001  maharashtra ' unhappy ' with delay in naming godbole nominee  - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  business standard , monday , 7 may 2001  reliance allowed to hawk power from patalganga to third parties  arijit de , s ravindran & renni abraham in mumbai  - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  the economic times , may 7 , 2001  no need of patalganga , bhadravati power : mseb  also appeared in the following newspaper :  the times of india , may 7 , 2001  ' no need of patalganga , bhadravati power '  - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  business standard , may 7 , 2001  global bankers ask govt to honour dpc obligations  - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  business standard  saturday , 5 may , 2001 ,  ge may pull out as dpc supplier , s ravindran in mumbai  - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  hindu businessline , may 5 , 2001  agenda for fresh talks with enron chalked out  - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  the economic times , may 6 , 2001  http : / / 216 . 34 . 146 . 167 : 8000 / servlet / form  godbole panel meets sans dabhol representation  - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  the economic times , may 5 , 2001  http : / / 216 . 34 . 146 . 167 : 8000 / servlet / form  ntpc not to buy power from enron : govt  - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  the times of india , may 7 , 2001  mseb recovers rs 3 . 06 cr arrears in one day  - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  the economic times , may 7 , 2001  enron ceo casts vote to save dpc , tina edwin & soma banerjee  amul ' s creative directors may have gone back to ad - libbing ' enron or  enr - off ' , but for the big kahuna at the american utility , dabhol is still a  worthwhile project . while the entire enron board had almost decided to call  it quits and proceed with the termination of the $ 2 . 9 - billion power project  at dabhol , the veto exercised by the company chairman kenneth lay has saved  the project \u0001 * - at least for the timebeing . sources said the meeting held on  tuesday at the energy major ' s headquarters in houston could have sounded the  death knell for the only big foreign investment in the indian power sector .  although the future of the project is still pretty uncertain with the lenders  unwilling to continue disbursements unless payment obligations are not  honoured and contractual obligations left unfulfilled , the veto exercised at  this juncture by the chairman of the parent company has come as a big boost  to the indian venture . company sources said : \" we do not know what went on  there but it is true that as of now we are not pulling out . \" with the  engineering procurement and construction contractors ge and equipment  suppliers bechtel too in a cautious mode mode , dpc was finding it even more  difficult to continue the construction of the project as per the schedules .  sources said the stand taken by the rest of the directors on the board would  be in view of the backlash that the company would have to face from its  shareholders if the project actually flopped . enron had similar bitter  experiences in pakistan and it was difficult for the parent company to then  justify such investments to the shareholders .  enron , which had planned a major investments in india ' s infrastructure  sectors such as oil and gas , lng , gas transportation , telecom and broadband  network , has already pulled out most of their personnel from some of these  operations . the company ' s mous with various other majors like indian oil  corporation , too , is in a limbo and the us major ' s stake in the oil and gas  venture is up for grabs . however , even though lay is still hoping to find a  solution to the controversy back home , both dpc and mseb are still to get  down to negotiations .  - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  the economic times , may 7 , 2001  maha sore over delay in naming godbole nominee  the maharashtra government has expressed ' unhappiness ' over the centre ' s  delay in appointing its nominee on the nine - member godbole committee to  renegotiate the power purchase agreement signed between enron - promoted  dabhol power company and state electricity board . \" the committee , which is  to hold discussions with enron officials from houston on may 11 , has only a  month ' s time for renegotiations and with dpc ' s termination notice threat  hanging on our head , time is actually running out . yet there is no official  to represent the union government , \" said a senior state government official .  \" there are media reports that the solicitor - general harish salve would be  appointed , but we are yet to hear anything from their side , \" he said .  the official said the state expected centre to announce its representative  before may 11 , as it would appreciate his crucial presence in the first  session of discussions with enron officials , lenders and gas suppliers .  sources in the mantralaya added the government had also been unhappy over  the centre ' s \" rigid stand \" on not allowing state - owned national thermal power  corporation to buy the excess capacity of dpc ' s total 2 , 184 - mw project .  \" let ntpc and power trading corporation of india come together and sell dpc ' s  surlpus power . we have already mooted this suggestion , but a favourable reply  is yet to come from the union power ministry , \" the official said .  - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  the times of india , 7 may , 2001  maharashtra ' unhappy ' with delay in naming godbole nominee  the maharashtra government has expressed ' unhappiness ' over the centre ' s  delay in appointing its nominee on the nine - member godbole committee to  renegotiate the power purchase agreement ( ppa ) signed between enron promoted  dabhol power company ( dpc ) and the maharashtra state electricity board  ( mseb ) . \" the committee , which is to hold discussions with enron officials  from houston on may 11 , has only a month ' s time for renegotiations and with  dpc ' s termination notice threat hanging on our head , time is actually running  out . yet there is no official to represent the union government , \" a senior  state government official said here on sunday . \" there are media reports that  solicitor general harish salve would be appointed , but we are yet to hear  anything from their side , \" he said .  the official said that the state expected the centre to announce their  representative before may 11 , as it would appreciate his crucial presence in  the first session of discussions with enron officials , lenders and gas  suppliers . sources in the mantralaya added that the government had also been  unhappy over the centre ' s rigid stand on not allowing state - owned national  thermal power corporation ( ntpc ) to buy the excess capacity of dpc ' s total  2 , 184 mw project . \" let ntpc and power trading corporation of india ( ptc ) come  together and sell dpc ' s surlpus power . we have already mooted this  suggestion , but a favourable reply is yet to come from the union power  ministry , \" the official said . the official said that the centre , which was  also responsible for dpc project as it has provided counter guarantee to  enron india , should form a special purpose vehicle for sale of the excess  power to other states . the state government ' s reaction comes in wake of union  power minister suresh prabhu ' s discussion with chief minister vilasrao  deshmukh in delhi few days ago . it was learnt that prabhu told deshmukh  \" there is no question of ntpc buying power from the project since long term  ppas have been signed by ntpc with the buying states \" .  deshmukh had suggested that the central power utility should sell excess  power over and above the 300 - 400 mw needed for the state from the dpc ' s 740  mw phase - i and soon to be commissioned phase - ii of 1 , 444 mw , to other needy  states . considering the high cost of power generated from dpc , which during  the recent months has hovered around rs 7 per unit as against an average cost  of rs 2 . 30 - 2 . 80 a unit from central and state utilities , there would be few  takers for the power from dabhol , the power minister reportedly said .  \" deficit states will buy dpc power only when the cost of power is brought  down , \" he said , adding power ministry would facilitate wheelng of this power  to the buyers .  - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  business standard , monday , 7 may 2001  reliance allowed to hawk power from patalganga to third parties  arijit de , s ravindran & renni abraham in mumbai  in an unusual departure from normal practice , the maharashtra government has  allowed the reliance group to sell power generated by its 447 - mw patalganga  power project directly to third parties if the maharashtra state  electricity board ( mseb ) does not lift power . the project \u0001 , s power purchase  agreement ( ppa ) has a clause to this effect . the state government \u0001 , s  permission to reliance to hawk power to third parties has to be seen in the  context of its dithering on forwarding to the centre the dabhol power  company \u0001 , s bid for mega power status so that it could sell power to third  parties .  dpc sources told business standard several weeks ago that the company \u0001 , s  application had been pending with the chief minister \u0001 , s office for months .  only now has the state government authorised the godbole committee to  negotiate with dpc on third party sales outside the state . the dpc project  is facing the threat of closure following mseb \u0001 , s inability to buy power from  it , thanks to the board \u0001 , s weak financial position . not only can the  reliance group sell power to third parties within maharashtra , but it can  sell power to utilities outside the state . the ppa does not expressly bar it  from doing so . nor does it specify the category of customers to whom power  can be sold . so , in effect , this suggests that the group could sell power to  industrial and commercial customers in maharashtra and emerge as a rival to  the mseb . the state electricity board derives over 80 per cent of its revenue  from such consumers .  apart from captive power plants , independent power producers in india are  allowed to sell power only to state electricity boards . they can sell power  outside the state only if they qualify for mega power project status . with  its 447 - mw capacity , the patalganga project is not eligible for such status  because mega power rojects are supposed to have a minimum capacity of 1 , 000  mw . speaking on the sidelines of a press conference last week , reliance  industries managing director anil ambani told business standard : a provision  in third parties . ambani was answering a question on whether the mseb \u0001 , s weak  financials and inability to offer escrow cover to the project as emphasised  in the godbole committee report set up to defuse the dabhol crisis would  derail the patalganga project .  the ppa does not have any express restriction as to third party sale outside  the state , a reliance spokesperson confirmed on friday in a faxed response  to questions . a senior mseb official explained that the state government  cleared private power projects some years ago on the basis of the  unrealistically high demand projections contained in a report by a former  mseb official . subsequently , it was realised that the state would be stuck  with excess power . so the reliance group was permitted to sell power to third  parties , he said . the patalganga project along with the ispat group \u0001 , s 1 , 082  mw bhadravati project has been put on hold till the godbole committee submits  its second  report .  - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  the economic times , may 7 , 2001  no need of patalganga , bhadravati power : mseb  the axe seems to have finally fallen on the much - delayed reliance  industries - promoted patalganga and ispat industries ' bhadravati power  projects in maharashtra as the state electricity board has firmly told the  government that \" there is no need of these projects nor their power \" . the  loss - making board has communicated to the government that mseb had \" no  interest \" in patalganga and bhadravati , as it did not have escrow - able  capacity and also that industrial demand for power had slowed down  tremendously in maharashtra , state government sources said here on sunday .  \" in last november itself , mseb had sent an official intimation to the state  government informing its decision in favour of cancellation of the two  projects on several grounds - - including they being unviable and  unaffordable , \" sources said . \" reliance ' s project is no different from that of  dpc ' s . patalganga is also naphtha - based and its ppa is on similar lines . . .  after the enron experience , mseb cannot even dream of another gas - based  power plant in the state , \" a senior mseb official said . he said mseb has  already asked the state government not to provide escrow to both the 447 - mw  patalganga and the 1 , 084 - mw coal - based bhadravati , \" as the us energy major  has almost squeezed us of all over finances \" . when contacted , mseb chairman  vinay bansal said : \" reliance and ispat projects have been put on hold as per  the godbole committee ' s recommendations \" , but expressed inability to give  further details .  currently , bhadravati and patalganga projects have been put on hold as per  godbole committee report , which was set up to review the dpc - mseb ppa and  energy scenario in maharashtra . \" can you go ahead with the project without an  escrow cover ? \" the committee was believed to have asked ispat and reliance  representatives , to which the reply had been negative , sources added .  sources said , as of now , both the projects have not been able to achieve  financial closure as leading financial institutions were not willing to  fund the projects which do not have a \" guaranteed payment \" mechanism from  mseb , which , incidentally it has promised to dpc . \" all the three were cleared  as ' fast - track ' projects , but other than enron , reliance and ispat have been  caught in a quagmire , especially bhadravati , which has been hanging afire  since last nine years , \" they added .  moreover , the mseb official opined that given the current situation , if dpc  calls it quits from india , bhadravati was a safer bet than reliance ' s  patalganga . patalganga ' s power would be mere 50 paise less than that of dpc ' s  that ranges anywhere around approximately rs 4 . 50 per unit to as high as rs  7 , while bhadravati ' s cost could be around rs 3 . 80 to rs 4 per unit , he  informed . mseb ' s installed capacity ended on march 31 , 2001 , wasl 4 , 000 mw and  it has generated 45 , 000 million units with transmission and distribution  losses as high as 39 per cent . ( pti )  - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  business standard , may 7 , 2001  global bankers ask govt to honour dpc obligations  tamal bandyopadhyay , surajeet dasgupta & santosh tiwary in mumbai / newdelhi  global arrangers for the dabhol power company have mounted fresh pressure on  the finance ministry to honour the union government \u0001 , s counter - guarantee and  have also set strict conditions for reconsidering the termination of the  power purchase agreement ( ppa ) between the dpc and the maharashtra state  electricity board ( mseb ) . in a related development , the dpc has sent a note  to all lenders saying they would have to bear the consequences of the turn  of events as they have prevented the dpc from serving the ppa termination  notice last month .  the lenders . in their turn , sent a statement - - prepared by the new  york - based legal firm white & case - - defending their stance saying they are  working in the best interest of the project . the lenders are expected to  meet in london over the next fortnight to take stock of the situation . the  deadline for resolving the issues are drawing to a close as 10 days of the  three - week reprieve have passed . at the dpc board meeting in london on may  25 , the lenders had managed to stall the issuance of the termination  notice and got three weeks \u0001 , time for themselves to convince the centre as  well as the maharashtra government to resolve the impasse on the  controversial project . in a letter to finance secretary ajit kumar dated  april 30 , the global arrangers said the government must own up its  responsibility and meet its obligations without further delay . among the  stiff conditions , set by the arrangers , are the demand that the central  government ensure payment of all the pending bills of mseb for december  2000 , january 2001 , february 2001 and march 2001 which remain unpaid  without any protest or reservation by may 7 ( monday ) .  any payment previously made under \u0001 & protest \u0001 8 should be made free and clear of  such protest or any other reservation , and the center should ensure timely  payment of future bills by mseb , they said . meanwhile , sources said that the  finance secretary was expected to meet the international lenders to the  dabhol projects in london stand on the issue . the lenders \u0001 , list of demands  also include asking mseb to take steps required under the existing  contracts to activate the escrow arrangements put in place at the time of  financial close of phase ii of the project by may 7 .  they have demanded that the union government and the maharashtra government  should take all required actions to ensure that no government agency will  take any step to impede the operation of phase i or the construction and  operation of phase ii without due cause . the lenders have also asked them to  ensure that the relevant customs authorities permit import of all goods and  equipment required for the project by may 21 . csfb , anz export finance ,  citi , bank of america and abn amro are the global arrangers for both phase i  as well as phase ii of the project .  the state bank of india , which is also a global arranger for phase ii , did  not sign the letter . \" ten days have passed since the lenders bought three  weeks time from the company delaying its declaration of the termination of  the ppa . since then , nothing has moved at the material level barring mseb ' s  payment of the january bill to the tune of rs 134 crore under protest , \" said  a source among the global arrangers . come forward to meet its obligations  the lenders are planning to meet around mid - may in london and this time  they will be left with no choice but to give the go - ahead to the company to  terminate the ppa unless the finance ministry comes forward to settle the  issue , the source added . the lenders are , however , not ready to take the  blame for any delay in the termination of ppa as implied by the company . the  white & case statement said the lenders are concerned about the fate of the  project and they are exploring all intermediate steps before choosing the  last option - - termination of ppa .  - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  business standard , saturday , 5 may , 2001  ge may pull out as dpc supplier , s ravindran in mumbai  after us - based bechtel , it is now the turn of general electric to review its  participation as equipment supplier to the controversial 2 , 184 - mw power  project in maharashtra , being set up by the dabhol power company . bechtel is  the epc contractor to the project while ge has supplied the equipment ,  primarily turbines . general electric , like bechtel , also holds 10 per cent in  dabhol power company ( dpc ) . and both bechtel and general electric are worried  about future payments from dpc . sources familiar with the project said that  so far dpc has not defaulted in its payments to general electric . what is  worrying general electric is the possible scenario after june 7 , when about  700 mw power will be commissioned after the second phase trial runs .  dpc and the maharashtra state electricity board ( mseb ) have been locked in a  payments dispute for months . if mseb continues with its stance , dpc in turn  may not be able to pay general electric . in such a situation , ge may walk out  of the project . a final decision will be taken only in june , said sources .  general electric did not respond to a faxed questionnaire sent by business  standard . senior executives at its public relations agency burson  marsteller roger pereira said that only dpc executives were authorised to  speak on the issue . the dpc spokesman declined to comment on the issue .  the first phase of the 740 mw has already been commissioned . after the second  phase of 1 , 444 mwis commissioned by december , 2001 , mseb will have to pay  dpc a minimum of rs 500 crore per month . the escrow account for this was to  have been made operational by april 7 , 2001 . mseb has refused to do this .  earlier , dpc had invoked the political force majeure clause in its contract  with the board . mseb is now arguing that the invocation of this clause has  absolved dpc of all its liabilities .  consequently , it will not operationalise the escrow account . this casts a  further shadow over dpc \u0001 , s ability to pay general electric and bechtel . this  is worrying the lenders to the project as well . the situation has taken a  turn for the worse with dpc practically refusing to re - negotiate the contract  for the second phase with the godbole panel constituted by the maharashtra  government .  - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  hindu businessline , may 5 , 2001  agenda for fresh talks with enron chalked out  officials of the state government , maharashtra state electricity board ( mseb )  and members of the madhav godbole committee , which recently submitted its  review on the dabhol power project , met here on saturday . the meeting was to  ` ` chart the agenda for renegotiation with enron officials , ' ' a senior mseb  official said . enron officials were scheduled to attend this meeting but  backed out on may 3 . enron had informed the state government that it would  not accept the recommendations of the godbole committee .  ` it is understandable that the company does not find the recommendations  acceptable . but the report is not bound to personal opinions , ' ' the official  said . the next meeting to decide the direction of renegotiation process with  enron is scheduled on may 11 .  - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  the economic times , may 6 , 2001  godbole panel meets sans dabhol representation  the godbole committee , set up for renegotiating the estranged power purchase  agreement between us energy major enron - promoted dabhol power company and the  state electricity board on saturday held its first internal meeting sans  representatives of the multinational . \" it was an internal meeting to take  stock of the current situation and decide on matter pertaining to the may 11  meet with officials of enron , ge , bechtel and dpc ' s foreign lenders , \" said  state government sources . the meeting , which lasted for almost four hours ,  discussed a strategy to present the committee ' s recommendations made public  last month , they said .  of the nine members of the committee , saturday ' s meeting was attended by five  members - - including godbole , mseb chairman vinay bansal , state energy  secretary v m lal , state finance secretary sudhir shrivastava and kirit  parekh of indira gandhi institute of developmental research . those absent  were hdfc chairman deepak parekh , teri director r k pachauri , former union  energy secretary eas sarma and yet - to - be - appointed representatives of the  centre and central electricity authority . the negotiating committee would  suggest solutions to bring down the exorbitant power tariff , separating of  the liquefied natural gas facility , restructuring of dpc and allowing sale of  excess power through central utilities mainly the national thermal power  corporation , said sources . ( pti  - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  the economic times , may 5 , 2001  ntpc not to buy power from enron : govt  the centre has ruled out the possibility of national thermal power  corporation buying power generated by us energy giant enron - promoted dabhol  power company . union power minister suresh prabhu is learnt to have stated  this during the meeting with maharashtra chief minister vilasrao deshmukh  last month , convened by the finance minister yashwant sinha to discuss the  enron crisis , said government sources on friday .  prabhu had pointed out that \" there is no question of ntpc buying power from  the project since long - term power purchase agreements have been signed by  ntpc with the buying states \" . maharashtra chief minister vilasrao deshmukh  during the meeting suggested that the central power utility sell the excess  power over and above the 300 - 400 mw needed for the state from the 740 mw  phase - i and soon - to - be - commissioned phase - ii of 1 , 444 - mw , to other needy  states . when contacted , prabhu said the entire controversy over payment  default by maharashtra state electricity board owing to high cost of power  generated by dpc had to be resolved between the state government , and dpc and  centre had very limited role to play . dpc has already slapped one  conciliation notice on the centre and three arbitration notices on the state  government over non - payment of dues amounting to rs 213 - crore - plus interest  rate towards bills due for the months of december 2000 and january 2001 . ( pti )  - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  the times of india , may 7 , 2001  mseb recovers rs 3 . 06 cr arrears in one day  in a special day - long drive , nagpur rural zone of maharashtra state  electricity board ( mseb ) has recovered rs 3 . 06 crore as arrears from the  defaulters who had to pay a handsome dividend , and disconnectedl 5 , 000  connections of erring customers last week . according to mseb sources , under  the drive , initiated by chief engineer manohar bapat , with the assistance of  about 5 , 000 employees including engineers , accounts staff and linesmen , a  door - to - door campaign was launched to meet 25 , 000 customers , leading to the  recovery of the dues . power supply to 15 , 000 customers were disconnected on  the spot due to non - payment of arrears in chandrapur , gadchiroli , wardha ,  bhandara , gondia and nagpur districts , it said in a release . the drive met  with stiff resistence from public and the police were called in at many  places to assist the powermen , it added .\n",
            "\n",
            "After preprocessing:\n",
            "\t:['enron' 'india' 'newsdesk' ... 'assist' 'powermen' 'added']\n"
          ]
        }
      ],
      "source": [
        "example_index = 4798\n",
        "example_email = X[example_index]\n",
        "treated_email = preprocess_text(example_email)\n",
        "print(f\"The email is:\\n\\t{example_email}\\n\\nAfter preprocessing:\\n\\t:{treated_email}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_n_0ZiPDxHC"
      },
      "source": [
        "Let's compute $P(\\text{spam}) \\cdot P(\\text{email} \\mid \\text{spam})$ and $P(\\text{ham}) \\cdot P(\\text{email} \\mid \\text{ham})$  in this case. You can do it by passing the argument `return_likelihood = True` in the `naive_bayes` function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7EZEJuN9DxHI",
        "outputId": "7588ef53-f478-4863-e618-1ce1d31dd1f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "spam_likelihood: 0.0\n",
            "ham_likelihood: 0.0\n"
          ]
        }
      ],
      "source": [
        "spam_likelihood, ham_likelihood = naive_bayes(treated_email, word_frequency = word_frequency, class_frequency = class_frequency, return_likelihood = True)\n",
        "print(f\"spam_likelihood: {spam_likelihood}\\nham_likelihood: {ham_likelihood}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QZalPk5aDxHK"
      },
      "source": [
        "Unfortunately, both spam and ham likelihood are $0$! This is clearly inaccurate! Let's compare the true and predicted labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z_lrpYDVDxHL",
        "outputId": "374dd19e-850f-4712-c4a8-89653c78c8d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The example email is labeled as: 0\n",
            "Naive bayes model classifies it as: 1\n"
          ]
        }
      ],
      "source": [
        "print(f\"The example email is labeled as: {Y[example_index]}\")\n",
        "print(f\"Naive bayes model classifies it as: {naive_bayes(treated_email, word_frequency, class_frequency)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4WkB1k0XDxHL"
      },
      "source": [
        "So, this is an email that would be incorrectly sent to the spam folder! However, this behavior is peculiar because both likelihoods are $0$. How can it be possible? The answer lies in the math behind it!\n",
        "\n",
        "The main computation for Naive Bayes:\n",
        "\n",
        "$$P(\\text{email} \\mid \\text{spam}) = P(\\text{word}_1 \\mid \\text{spam}) \\cdot P(\\text{word}_2 \\mid \\text{spam}) \\cdots P(\\text{word}_n \\mid \\text{spam})$$\n",
        "\n",
        "It is a product of **every** word in the email."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h-_KgIcEDxHM",
        "outputId": "92d632f8-a9a8-4e42-ed21-948a91eb13e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The example email has: 2657 words in the product.\n"
          ]
        }
      ],
      "source": [
        "print(f\"The example email has: {len(treated_email)} words in the product.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4DapVLZDDxHM"
      },
      "source": [
        "So the email in question has $2657$ words! Let's compute the value $P(\\text{word} \\mid \\text{ham})$ for the first 3 words in the email:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ZlOcbOUDxHN",
        "outputId": "637bad11-a7f3-46fa-8995-ff996ebcfa76"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Word: enron. P(enron | ham) = 0.5957324106113033\n",
            "Word: india. P(india | ham) = 0.01787773933102653\n",
            "Word: newsdesk. P(newsdesk | ham) = 0.0017301038062283738\n"
          ]
        }
      ],
      "source": [
        "for i in range(3):\n",
        "    word = treated_email[i]\n",
        "    p_word_given_ham = prob_word_given_class(word, cls = 'ham', word_frequency = word_frequency, class_frequency = class_frequency)\n",
        "    print(f\"Word: {word}. P({word} | ham) = {p_word_given_ham}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QWVLyV_-DxHN"
      },
      "source": [
        "Given that they are all probabilities, they are numbers between $0$ and $1$. So, the product being performed is a product of $2657$ numbers between $0$ and $1$. In the best-case scenario, where every word has a probability in the magnitude of $10^{-1}$ (similar to the first word in the example above), the resulting probability would be in the magnitude of $10^{-2657}$—a **very small number** that is challenging for any computer to handle with precision. Let's examine Python's limit on floating-point numbers (decimal numbers):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mxP2NgcXDxHO",
        "outputId": "0c912d34-9dd2-4db9-b35b-9954b06caa81"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sys.float_info(max=1.7976931348623157e+308, max_exp=1024, max_10_exp=308, min=2.2250738585072014e-308, min_exp=-1021, min_10_exp=-307, dig=15, mant_dig=53, epsilon=2.220446049250313e-16, radix=2, rounds=1)\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "\n",
        "print(sys.float_info)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CW7sZKahDxHP"
      },
      "source": [
        "The minimum float value has a magnitude of $10^{-308}$, significantly larger than $10^{-2657}$. Consequently, Python interprets the result of the product as $0$ at some point, leading to the loss of all information. In other words, the way our algorithm is currently written, past a certain length, all emails are being classified as spam. Given the nature of this issue, rooted in the very large product required by Naive Bayes, it is crucial to address the problem.\n",
        "\n",
        "#### 5.1.1 The Underflow Problem\n",
        "\n",
        "This challenge is termed an **underflow problem**, indicating that we are dealing with exceedingly small numbers beyond the computer's precision. In this case, the root cause is the **very large product** involved in Naive Bayes calculations. Fortunately, there is a solution to this issue.\n",
        "\n",
        "In Naive Bayes, the specific values of probabilities are not critical since the algorithm solely **compares values**. This is why the denominators in the following equations have been disregarded:\n",
        "\n",
        "$$ P(\\text{spam} \\mid \\text{email}) = \\frac{P(\\text{spam}) \\cdot P(\\text{email} \\mid \\text{spam})}{P(\\text{email})} $$\n",
        "$$ P(\\text{ham} \\mid \\text{email}) = \\frac{P(\\text{ham}) \\cdot P(\\text{email} \\mid \\text{ham})}{P(\\text{email}) } $$\n",
        "\n",
        "Given that the goal is to identify the greater value between the two, and they share the same positive denominator, only the numerators matter. Specifically, the actual values of these two products:\n",
        "\n",
        "$$P(\\text{spam}) \\cdot P(\\text{email} \\mid \\text{spam})$$\n",
        "$$P(\\text{ham}) \\cdot P(\\text{email} \\mid \\text{ham})$$\n",
        "\n",
        "are irrelevant, as long as you can tell which one is larger than the other.\n",
        "\n",
        "If there exists a function that can be applied to these quantities and **preserves the ordering**, then comparing the outputs of these values in such a function will determine the class with the maximum value (although the actual numeric value may differ).\n",
        "\n",
        "Any **strictly increasing function** possesses this property: it preserves the maximum **point**. Therefore, the idea is to find a **increasing function** that aids in handling the large product faced by the Naive Bayes algorithm. We'll use the $\\log$ function. Since $\\log$ is increasing, it preserves the maximum point. Therefore, we can compare the following quantities:\n",
        "\n",
        "$$\\log \\left(P(\\text{spam}) \\cdot P(\\text{email} \\mid \\text{spam}) \\right)$$\n",
        "$$\\log \\left(P (\\text{ham}) \\cdot P(\\text{email} \\mid \\text{ham}) \\right)$$\n",
        "\n",
        "And choose the maximum value among these new quantities. Denoting the class as either spam or ham:\n",
        "\n",
        "$$\\log \\left(P(\\text{class}) \\cdot P(\\text{email} \\mid \\text{class}) \\right) = \\log \\left(P(\\text{class}) \\right) + \\log \\left( P(\\text{email} \\mid \\text{class}) \\right)$$\n",
        "\n",
        "And\n",
        "\n",
        "$$\\log \\left( P(\\text{email} \\mid \\text{class}) \\right) = \\log  \\left(P(\\text{word}_1 \\mid \\text{class}) \\cdot P(\\text{word}_2 \\mid \\text{class}) \\cdots P(\\text{word}_n \\mid \\text{class}) \\right) = \\log  \\left(P(\\text{word}_1 \\mid \\text{class}) \\right) + \\log \\left(P(\\text{word}_2 \\mid \\text{class})\\right) + \\cdots + \\log \\left( P(\\text{word}_n \\mid \\text{class}) \\right) $$\n",
        "\n",
        "With this approach, we have successfully transformed a large product into a large summation, a significantly more numerically stable operation. Now, we will improve our functions with this new technique! We need to adjust two functions:\n",
        "\n",
        "- `prob_email_given_class` - replace the probability word product by the sum of the logs\n",
        "- `naive_bayes` - replace the product $P(\\text{class}) \\cdot P(\\text{email} \\mid \\text{class})$ by its respective sum of log.\n",
        "\n",
        "The new functions will be called `log_prob_email_given_class` and `log_naive_bayes`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C7thBss5DxHP"
      },
      "outputs": [],
      "source": [
        "def log_prob_email_given_class(treated_email, cls, word_frequency, class_frequency):\n",
        "    \"\"\"\n",
        "    Calculate the log probability of an email being of a certain class (e.g., spam or ham) based on treated email content.\n",
        "\n",
        "    Parameters:\n",
        "    - treated_email (list): A list of treated words in the email.\n",
        "    - cls (str): The class label ('spam' or 'ham')\n",
        "\n",
        "\n",
        "    Returns:\n",
        "    - float: The log probability of the given email belonging to the specified class.\n",
        "    \"\"\"\n",
        "\n",
        "    # prob starts at 0 because it will be updated by summing it with the current log(P(word | class)) in every iteration\n",
        "    prob = 0\n",
        "\n",
        "    for word in treated_email:\n",
        "        # Only perform the computation for words that exist in the word frequency dictionary\n",
        "        if word in word_frequency.keys():\n",
        "            # Update the prob by summing it with log(P(word | class))\n",
        "            prob += np.log(prob_word_given_class(word, cls,word_frequency, class_frequency))\n",
        "\n",
        "    return prob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-btJ6CrMDxHQ",
        "outputId": "08fc405b-7eb8-4ea0-a3ef-f7c84af52de8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "For word schedule:\n",
            "\tP(schedule | spam) = 0.008976660682226212\n",
            "\tlog(P(schedule | spam)) = -4.713127327493184\n"
          ]
        }
      ],
      "source": [
        "# Consider an email with only one word, so it reduces to compute the value P(word | class) or log(P(word | class)).\n",
        "one_word_email = ['schedule']\n",
        "word = one_word_email[0]\n",
        "prob_spam = prob_email_given_class(one_word_email, cls = 'spam',word_frequency = word_frequency, class_frequency = class_frequency)\n",
        "log_prob_spam = log_prob_email_given_class(one_word_email, cls = 'spam',word_frequency = word_frequency, class_frequency = class_frequency)\n",
        "print(f\"For word {word}:\\n\\tP({word} | spam) = {prob_spam}\\n\\tlog(P({word} | spam)) = {log_prob_spam}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2iFr5ehZDxHR"
      },
      "source": [
        "Note that the $\\text{log}$ was capable of transforming a small number into a negative number with a good magnitude. Furthermore, now the algorithm is performing a sum instead of product."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "15Q3E-pBDxHR"
      },
      "outputs": [],
      "source": [
        "def log_naive_bayes(treated_email, word_frequency, class_frequency, return_likelihood = False):\n",
        "    \"\"\"\n",
        "    Naive Bayes classifier for spam detection, comparing the log probabilities instead of the actual probabilities.\n",
        "\n",
        "    This function calculates the log probability of an email being spam (1) or ham (0)\n",
        "    based on the Naive Bayes algorithm. It uses the conditional probabilities of the\n",
        "    treated_email given spam and ham, as well as the prior probabilities of spam and ham\n",
        "    classes. The final decision is made by comparing the calculated probabilities.\n",
        "\n",
        "    Parameters:\n",
        "    - treated_email (list): A preprocessed representation of the input email.\n",
        "    - return_likelihood (bool): If true, it returns the log_likelihood of both spam and ham.\n",
        "\n",
        "    Returns:\n",
        "    - int: 1 if the email is classified as spam, 0 if classified as ham.\n",
        "    \"\"\"\n",
        "\n",
        "    # Compute P(email | spam) with the new log function\n",
        "    log_prob_email_given_spam = log_prob_email_given_class(treated_email, cls = 'spam',word_frequency = word_frequency, class_frequency = class_frequency)\n",
        "\n",
        "    # Compute P(email | ham) with the function you defined just above\n",
        "    log_prob_email_given_ham = log_prob_email_given_class(treated_email, cls = 'ham',word_frequency = word_frequency, class_frequency = class_frequency)\n",
        "\n",
        "    # Compute P(spam) using the class_frequency dictionary and using the formula #spam emails / #total emails\n",
        "    p_spam = class_frequency['spam']/(class_frequency['ham'] + class_frequency['spam'])\n",
        "\n",
        "    # Compute P(ham) using the class_frequency dictionary and using the formula #ham emails / #total emails\n",
        "    p_ham = class_frequency['ham']/(class_frequency['ham'] + class_frequency['spam'])\n",
        "\n",
        "    # Compute the quantity log(P(spam)) + log(P(email | spam)), let's call it log_spam_likelihood\n",
        "    log_spam_likelihood = np.log(p_spam) + log_prob_email_given_spam\n",
        "\n",
        "    # Compute the quantity P(ham) * P(email | ham), let's call it ham_likelihood\n",
        "    log_ham_likelihood = np.log(p_ham) + log_prob_email_given_ham\n",
        "\n",
        "    # In case of passing return_likelihood = True, then return the desired tuple\n",
        "    if return_likelihood == True:\n",
        "        return (log_spam_likelihood, log_ham_likelihood)\n",
        "\n",
        "    # Compares both values and choose the class corresponding to the higher value.\n",
        "    # As the logarithm is an increasing function, the class with the higher value retains this property.\n",
        "    if log_spam_likelihood >= log_ham_likelihood:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vPHkbD_YDxHS"
      },
      "source": [
        "Revisiting the example from the beginning of the section, I compute `log_spam_likelihood` and `log_ham_likelihood`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jy-4-T3yDxHS",
        "outputId": "807b0049-bae4-433c-d121-1cc7dbe947b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "log_spam_likelihood: -11532.137516538043\n",
            "log_ham_likelihood: -10281.893202145671\n"
          ]
        }
      ],
      "source": [
        "log_spam_likelihood, log_ham_likelihood = log_naive_bayes(treated_email,word_frequency = word_frequency, class_frequency = class_frequency,return_likelihood = True)\n",
        "print(f\"log_spam_likelihood: {log_spam_likelihood}\\nlog_ham_likelihood: {log_ham_likelihood}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F8KmR1ZnDxHT"
      },
      "source": [
        "Now there are two distinct non-zero numbers! Note the higher one is the `log_ham_likelihood`, therefore the `log_naive_bayes` function will correctly predict this email as ham:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gYQOf-arDxHT",
        "outputId": "301df640-0466-4a86-aaa4-eebd00b9e510"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The example email is labeled as: 0\n",
            "Log Naive bayes model classifies it as: 0\n"
          ]
        }
      ],
      "source": [
        "print(f\"The example email is labeled as: {Y[example_index]}\")\n",
        "print(f\"Log Naive bayes model classifies it as: {log_naive_bayes(treated_email,word_frequency = word_frequency, class_frequency = class_frequency)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2PbLZcicDxHU"
      },
      "source": [
        "With this enhanced algorithm, the new accuracy is:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C8jSZ1hCDxHU",
        "outputId": "afe3df74-fffe-4417-af90-4c1ffae61a41"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of true positives is: 249\n",
            "The number of true negatives is: 888\n",
            "The accuracy is: 0.9921\n"
          ]
        }
      ],
      "source": [
        "# Let's get the predictions for the test set:\n",
        "\n",
        "# Create an empty list to store the predictions\n",
        "Y_pred = []\n",
        "\n",
        "\n",
        "# Iterate over every email in the test set\n",
        "for email in X_test:\n",
        "    # Perform prediction\n",
        "    prediction = log_naive_bayes(email,word_frequency = word_frequency, class_frequency = class_frequency)\n",
        "    # Add it to the list\n",
        "    Y_pred.append(prediction)\n",
        "\n",
        "# Get the number of true positives:\n",
        "true_positives = get_true_positives(Y_test, Y_pred)\n",
        "\n",
        "# Get the number of true negatives:\n",
        "true_negatives = get_true_negatives(Y_test, Y_pred)\n",
        "\n",
        "print(f\"The number of true positives is: {true_positives}\\nThe number of true negatives is: {true_negatives}\")\n",
        "\n",
        "# Compute the accuracy by summing true negatives with true positives and dividing it by the total number of elements in the dataset.\n",
        "# Since both Y_pred and Y_test have the same length, it does not matter which one you use.\n",
        "accuracy = (true_positives + true_negatives)/len(Y_test)\n",
        "\n",
        "print(f\"The accuracy is: {accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ivfIUeAADxHV"
      },
      "source": [
        "This is a **huge** improvement! We just increased the model's accuracy from 84.82% to 99.21% in the test set! An increase of almost 17%."
      ]
    }
  ],
  "metadata": {
    "grader_version": "1",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}